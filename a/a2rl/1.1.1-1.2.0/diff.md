# Comparing `tmp/a2rl-1.1.1-py3-none-any.whl.zip` & `tmp/a2rl-1.2.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,32 +1,32 @@
-Zip file size: 213023 bytes, number of entries: 30
--rw-r--r--  2.0 unx     2223 b- defN 22-Sep-21 15:07 a2rl/__init__.py
--rw-r--r--  2.0 unx    32274 b- defN 22-Sep-21 15:07 a2rl/_dataframe.py
--rw-r--r--  2.0 unx    13677 b- defN 22-Sep-21 15:07 a2rl/_io.py
--rw-r--r--  2.0 unx     1304 b- defN 22-Sep-21 15:07 a2rl/_metadatadict.py
--rw-r--r--  2.0 unx      154 b- defN 22-Sep-21 15:07 a2rl/config.yaml
--rw-r--r--  2.0 unx     6413 b- defN 22-Sep-21 15:07 a2rl/nbtools.py
--rw-r--r--  2.0 unx        0 b- defN 22-Sep-21 15:07 a2rl/py.typed
--rw-r--r--  2.0 unx    61786 b- defN 22-Sep-21 15:07 a2rl/simulator.py
--rw-r--r--  2.0 unx    19356 b- defN 22-Sep-21 15:07 a2rl/tokenizer.py
--rw-r--r--  2.0 unx    19506 b- defN 22-Sep-21 15:07 a2rl/utils.py
--rw-r--r--  2.0 unx        0 b- defN 22-Sep-21 15:07 a2rl/dataset/__init__.py
--rw-r--r--  2.0 unx   362007 b- defN 22-Sep-21 15:07 a2rl/dataset/chiller/data.csv
--rw-r--r--  2.0 unx      178 b- defN 22-Sep-21 15:07 a2rl/dataset/chiller/metadata.yaml
--rw-r--r--  2.0 unx   228884 b- defN 22-Sep-21 15:07 a2rl/dataset/rtu/data.csv
--rw-r--r--  2.0 unx      308 b- defN 22-Sep-21 15:07 a2rl/dataset/rtu/metadata.yaml
--rw-r--r--  2.0 unx        0 b- defN 22-Sep-21 15:07 a2rl/experimental/__init__.py
--rw-r--r--  2.0 unx      651 b- defN 22-Sep-21 15:07 a2rl/experimental/lightgpt/__init__.py
--rw-r--r--  2.0 unx      154 b- defN 22-Sep-21 15:07 a2rl/experimental/lightgpt/config.yaml
--rw-r--r--  2.0 unx     1711 b- defN 22-Sep-21 15:07 a2rl/experimental/lightgpt/lr_decay.py
--rw-r--r--  2.0 unx    10889 b- defN 22-Sep-21 15:07 a2rl/experimental/lightgpt/model.py
--rw-r--r--  2.0 unx     6974 b- defN 22-Sep-21 15:07 a2rl/experimental/lightgpt/simulator.py
--rw-r--r--  2.0 unx        0 b- defN 22-Sep-21 15:07 a2rl/mingpt/__init__.py
--rw-r--r--  2.0 unx     9458 b- defN 22-Sep-21 15:07 a2rl/mingpt/model.py
--rw-r--r--  2.0 unx     5553 b- defN 22-Sep-21 15:07 a2rl/mingpt/trainer.py
--rw-r--r--  2.0 unx    10084 b- defN 22-Sep-21 15:07 a2rl-1.1.1.dist-info/LICENSE
--rw-r--r--  2.0 unx     4792 b- defN 22-Sep-21 15:07 a2rl-1.1.1.dist-info/METADATA
--rw-r--r--  2.0 unx       67 b- defN 22-Sep-21 15:07 a2rl-1.1.1.dist-info/NOTICE
--rw-r--r--  2.0 unx       92 b- defN 22-Sep-21 15:07 a2rl-1.1.1.dist-info/WHEEL
--rw-r--r--  2.0 unx        5 b- defN 22-Sep-21 15:07 a2rl-1.1.1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     2395 b- defN 22-Sep-21 15:07 a2rl-1.1.1.dist-info/RECORD
-30 files, 800895 bytes uncompressed, 209217 bytes compressed:  73.9%
+Zip file size: 214501 bytes, number of entries: 30
+-rw-r--r--  2.0 unx     2223 b- defN 23-May-22 10:28 a2rl/__init__.py
+-rw-r--r--  2.0 unx    32274 b- defN 23-May-22 10:28 a2rl/_dataframe.py
+-rw-r--r--  2.0 unx    13581 b- defN 23-May-22 10:28 a2rl/_io.py
+-rw-r--r--  2.0 unx     1304 b- defN 23-May-22 10:28 a2rl/_metadatadict.py
+-rw-r--r--  2.0 unx      154 b- defN 23-May-22 10:28 a2rl/config.yaml
+-rw-r--r--  2.0 unx     6413 b- defN 23-May-22 10:28 a2rl/nbtools.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-22 10:28 a2rl/py.typed
+-rw-r--r--  2.0 unx    67245 b- defN 23-May-22 10:28 a2rl/simulator.py
+-rw-r--r--  2.0 unx    19356 b- defN 23-May-22 10:28 a2rl/tokenizer.py
+-rw-r--r--  2.0 unx    19505 b- defN 23-May-22 10:28 a2rl/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-22 10:28 a2rl/dataset/__init__.py
+-rw-r--r--  2.0 unx   362007 b- defN 23-May-22 10:28 a2rl/dataset/chiller/data.csv
+-rw-r--r--  2.0 unx      178 b- defN 23-May-22 10:28 a2rl/dataset/chiller/metadata.yaml
+-rw-r--r--  2.0 unx   228884 b- defN 23-May-22 10:28 a2rl/dataset/rtu/data.csv
+-rw-r--r--  2.0 unx      308 b- defN 23-May-22 10:28 a2rl/dataset/rtu/metadata.yaml
+-rw-r--r--  2.0 unx        0 b- defN 23-May-22 10:28 a2rl/experimental/__init__.py
+-rw-r--r--  2.0 unx      651 b- defN 23-May-22 10:28 a2rl/experimental/lightgpt/__init__.py
+-rw-r--r--  2.0 unx      154 b- defN 23-May-22 10:28 a2rl/experimental/lightgpt/config.yaml
+-rw-r--r--  2.0 unx     1711 b- defN 23-May-22 10:28 a2rl/experimental/lightgpt/lr_decay.py
+-rw-r--r--  2.0 unx    10889 b- defN 23-May-22 10:28 a2rl/experimental/lightgpt/model.py
+-rw-r--r--  2.0 unx     6974 b- defN 23-May-22 10:28 a2rl/experimental/lightgpt/simulator.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-22 10:28 a2rl/mingpt/__init__.py
+-rw-r--r--  2.0 unx     9458 b- defN 23-May-22 10:28 a2rl/mingpt/model.py
+-rw-r--r--  2.0 unx     5550 b- defN 23-May-22 10:28 a2rl/mingpt/trainer.py
+-rw-r--r--  2.0 unx    10084 b- defN 23-May-22 10:28 a2rl-1.2.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     5445 b- defN 23-May-22 10:28 a2rl-1.2.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       67 b- defN 23-May-22 10:28 a2rl-1.2.0.dist-info/NOTICE
+-rw-r--r--  2.0 unx       92 b- defN 23-May-22 10:28 a2rl-1.2.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        5 b- defN 23-May-22 10:28 a2rl-1.2.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2395 b- defN 23-May-22 10:28 a2rl-1.2.0.dist-info/RECORD
+30 files, 806907 bytes uncompressed, 210695 bytes compressed:  73.9%
```

## zipnote {}

```diff
@@ -66,26 +66,26 @@
 
 Filename: a2rl/mingpt/model.py
 Comment: 
 
 Filename: a2rl/mingpt/trainer.py
 Comment: 
 
-Filename: a2rl-1.1.1.dist-info/LICENSE
+Filename: a2rl-1.2.0.dist-info/LICENSE
 Comment: 
 
-Filename: a2rl-1.1.1.dist-info/METADATA
+Filename: a2rl-1.2.0.dist-info/METADATA
 Comment: 
 
-Filename: a2rl-1.1.1.dist-info/NOTICE
+Filename: a2rl-1.2.0.dist-info/NOTICE
 Comment: 
 
-Filename: a2rl-1.1.1.dist-info/WHEEL
+Filename: a2rl-1.2.0.dist-info/WHEEL
 Comment: 
 
-Filename: a2rl-1.1.1.dist-info/top_level.txt
+Filename: a2rl-1.2.0.dist-info/top_level.txt
 Comment: 
 
-Filename: a2rl-1.1.1.dist-info/RECORD
+Filename: a2rl-1.2.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## a2rl/__init__.py

```diff
@@ -52,8 +52,8 @@
     sample_dataset_path,
     save_metadata,
 )
 from ._metadatadict import MetadataDict
 from .simulator import AutoTokenizer, GPTBuilder, Simulator, SimulatorDataset, SimulatorWrapper
 from .tokenizer import DiscreteTokenizer, Tokenizer
 
-__version__ = "1.1.1"
+__version__ = "1.2.0"
```

## a2rl/_io.py

```diff
@@ -183,20 +183,20 @@
     #: ``2H``, ``D``.
     frequency: None | str = None
 
     #: ``dict[str, Any]`` - Additional custom metadata.
     tags: dict[str, Any] = field(default_factory=dict)
 
     def __post_init__(self) -> None:
-        check_type("states", self.states, List[str])
-        check_type("actions", self.actions, List[str])
-        check_type("rewards", self.rewards, List[str])
-        check_type("forced_categories", self.forced_categories, Optional[List[str]])
-        check_type("frequency", self.frequency, Optional[str])
-        check_type("tags", self.tags, Dict[str, Any])
+        check_type(self.states, List[str])
+        check_type(self.actions, List[str])
+        check_type(self.rewards, List[str])
+        check_type(self.forced_categories, Optional[List[str]])
+        check_type(self.frequency, Optional[str])
+        check_type(self.tags, Dict[str, Any])
 
 
 def read_metadata(yaml_file: str | Path) -> Metadata:
     """Load a YAML file into an in-memory metadata object.
 
     Arguments:
         yaml_file: Path to the input YAML file.
@@ -333,26 +333,27 @@
             <BLANKLINE>
             forced_categories:
             - a
             <BLANKLINE>
             tags: {}
             <BLANKLINE>
     """
+
     # Based on https://github.com/yaml/pyyaml/issues/127#issuecomment-525800484
     class BlankLiner(yaml.SafeDumper):
         def write_line_break(self, data=None):
             super().write_line_break(data)
 
             if len(self.indents) == 1:
                 super().write_line_break()
 
     if isinstance(metadata, Metadata):
         m = metadata
     elif isinstance(metadata, dict):
-        check_type("metadata_dictionary", metadata, MetadataDict)
+        check_type(metadata, MetadataDict)
         m = Metadata(**metadata)
 
     p = yaml_file if isinstance(yaml_file, Path) else Path(yaml_file)
     d = asdict(m)
     if compact:
         d = {k: v for k, v in d.items() if v is not None}
     with p.open("w") as f:
```

## a2rl/simulator.py

```diff
@@ -243,15 +243,14 @@
     df: WiDataFrame = field(init=True, repr=False)
     block_size_row: int = field(init=True, repr=False)
     train_ratio: float = 1.0
     copy: bool = field(default=True, repr=False)
     field_tokenizer: DiscreteTokenizer = field(default_factory=DiscreteTokenizer, repr=False)
 
     def __post_init__(self):
-
         self.df = self.df.trim(self.copy)
         self.columns = self.df.columns
         self.column_len = len(self.columns)
         self.state_columns = self.df.states
         self.action_columns = self.df.actions
         self.reward_columns = self.df.rewards
         self.df_shape: tuple = self.df.shape
@@ -540,29 +539,25 @@
             x = torch.cat((x, ix), dim=1)
 
         if self.manage_tensor_placement and self.device != "cpu":
             x = x.cpu()
         x_np = x.numpy().flatten()
         return x_np
 
-    def evaluate(self, context_len: int = 20, sample: bool = True, horizon: int = None) -> Axes:
+    def evaluate(self, context_len: int = 20, sample: bool = True, horizon: int = 200) -> Axes:
         """This is to evaluate the raw GPT model.
 
         Arguments:
             context_len: These is a sequence of GPT tokens
             sample: Enable sampling.
             horizon: The number of GPT token to predict based on input GPT token sequence.
 
         Returns:
             Matplotlib Axes.
         """
-
-        if horizon is None:
-            horizon = 200
-
         test_seq = self.tokenizer.df_tokenized.sequence[:context_len]
         test_gpt_token = self.tokenizer.gpt_tokenize(test_seq)
         preds_gpt = self.sample(test_gpt_token, n_steps=(horizon), sample=sample)
         preds_seq = self.tokenizer.gpt_inverse_tokenize(preds_gpt)
 
         true_ser = pd.Series(
             self.tokenizer.df_tokenized.sequence[: horizon + context_len], name="true"
@@ -1058,18 +1053,21 @@
 
         return state, reward, done, {}
 
     def render(self, mode="human"):
         raise NotImplementedError("render() is not supported.")
 
     def _gpt_predict(self, seq: torch.Tensor, block_size: int) -> torch.Tensor:
-        """Predict next GPT token given the input sequence of GPT tokens.
+        """Predict next GPT token given the input sequence of GPT tokens, where the sequence length
+        is subjected to at most ``block_size`` tokens.
 
         Arguments:
-            seq: GPT tokens, 2D dimension (n_sample, seq_length).
+            seq: GPT tokens as a 2D array ``(n_sample, seq_length)``. If ``seq_length`` is greater
+                than ``block_size``, then this input sequence will be silently trimmed to
+                ``(batch_size, block_size)``.
             block_size: maximum context window size.
 
         Returns:
             Logits for next GPT token. 2D dimension (n_sample, vocab_size).
         """
         if seq.dim() != 2:
             raise ValueError(f"seq must have dim of 2, but {seq.dim()} is given.")
@@ -1245,14 +1243,125 @@
         seq = seq.ravel()
         valid_token = list(self.tokenizer._gpt_token_to_tokenized_val_map.values())
         neighbors_idx = self.tokenizer.token_neighbors.kneighbors(
             seq.reshape(-1, 1), return_distance=False
         )
         return np.array([valid_token[i] for i in neighbors_idx.ravel()])
 
+    @torch.no_grad()
+    def beam_search_n_steps(  # noqa: C901
+        self,
+        seq: np.ndarray,
+        n_steps: int,
+        beam_width: int,
+        randomness: bool = False,
+        overwrite_valid_tokens: dict[str, list[int]]
+        | None = None,  # {"col_name": [valid tokens], ...}
+        start_col_idx: int | None = None,
+        is_gpt_token: bool = False,
+        return_logprobs: bool = False,
+    ):
+        """This function largely replaces A2RL :meth:`Simulator.gpt_sample_n_steps()`. It does not
+        concern states/actions/rewards and only generates the next ``N`` tokens using beam search.
+        This function is to be used by a planner.
+
+        Args:
+            seq: A sequence of tokens (1-dimensional only)
+            n_steps: number of tokens to generate
+            beam_width: number of beams used in beam search. Must be <= the vocab size in
+                the starting column (determined by both valid tokens of that column &
+                ``overwrite_valid_tokens``, if used).
+                Setting this to 1 is equivalent to behaviour cloning.
+            randomness: if True, will use multinomial sampling of the top-n tokens instead of
+                deterministic beam search.
+            overwrite_valid_tokens: ``dict[ col_name : list of GPT tokens ]``, overwrite the valid
+                tokens in a column, useful if additional constriants need to be applied during
+                inference.
+            start_col_index: Indicate the starting dataframe column index. Default to
+                ``len(seq) % len(columns)`` if None
+            is_gpt_token: whether the tokens in ``seq`` are GPT tokens or DataFrame tokens
+            return_logprobs: if True, the return will be a tuple of tokens and the accumulated
+                logprobs of each beam.
+        """
+        if seq.ndim != 1:
+            raise NotImplementedError("batching not implemented")
+        if overwrite_valid_tokens is None:
+            overwrite_valid_tokens = dict()
+
+        if not is_gpt_token:
+            # seq and overwrite_valid_tokens are provided in Dataframe tokens
+            # Need to convert them to GPT tokens first
+            seq = self.tokenizer.gpt_tokenize(seq.ravel()).reshape(seq.shape)
+
+        columns = self.tokenizer.columns
+        if start_col_idx is None:  # assume seq is in SARSAR... format
+            start_col_idx = len(seq) % len(columns)
+
+        seq_tensor = torch.tensor(seq, device=self.device).reshape(1, -1)
+        accum_logprobs = torch.zeros(1, device=self.device)
+
+        for step in range(n_steps):
+            col_idx = (start_col_idx + step) % len(columns)
+            col_name = columns[col_idx]
+            if col_name in overwrite_valid_tokens:
+                valid_tokens = np.array(overwrite_valid_tokens[col_name])
+
+                if not is_gpt_token:
+                    valid_tokens = self.tokenizer.gpt_tokenize(np.asarray(valid_tokens))
+            else:
+                valid_tokens = np.array(
+                    get_valid_gpt_token_idx(
+                        self.tokenizer._col_eligible_index,
+                        col_idx,
+                        self.tokenizer.simulator_ds,
+                    )
+                )
+
+            valid_tokens_tensor = torch.tensor(valid_tokens, device=self.device)
+
+            if valid_tokens_tensor.size(0) == 1:
+                seq_tensor = torch.hstack(
+                    (seq_tensor, valid_tokens_tensor.tile(seq_tensor.size(0), 1))
+                )
+                continue
+
+            logits = self._gpt_predict(
+                seq_tensor, self.tokenizer.block_size
+            )  # shape = (beam_width, vocab_size)
+            logits = logits[:, valid_tokens_tensor]
+            logprobs = F.log_softmax(logits, dim=1)
+            accum_logprobs = (logprobs + accum_logprobs.reshape(-1, 1)).flatten()
+
+            if beam_width > accum_logprobs.numel():
+                raise ValueError(
+                    "beam_width cannot be larger than the vocab size of the starting column. "
+                    f"Expect beam_width <= {accum_logprobs.numel()}, got {beam_width}"
+                )
+
+            if randomness:
+                top_indices = torch.multinomial(accum_logprobs.exp(), beam_width, replacement=False)
+                accum_logprobs = accum_logprobs[top_indices]
+            else:
+                accum_logprobs, top_indices = torch.topk(accum_logprobs, beam_width)
+            seq_indices = torch.div(top_indices, valid_tokens_tensor.size(0), rounding_mode="floor")
+            token_indices = torch.remainder(top_indices, valid_tokens_tensor.size(0))
+
+            seq_tensor = torch.hstack(
+                (seq_tensor[seq_indices], valid_tokens_tensor[token_indices].reshape(-1, 1))
+            )
+
+        seq, accum_logprobs = seq_tensor.cpu().numpy(), accum_logprobs.cpu().numpy()
+        if not is_gpt_token:
+            seq = self.tokenizer.gpt_inverse_tokenize(seq.ravel()).reshape(seq.shape)
+
+        if return_logprobs:
+            return seq, accum_logprobs
+
+        return seq
+
     def sample(
         self,
         seq: np.ndarray,
         max_size: int = 3,
         as_token: bool = False,
         correct_unseen_token: bool = True,
     ) -> wi.WiDataFrame:
@@ -1272,31 +1381,33 @@
                 [10, 11], # From context [1,2]
                 [12, 13], # From context [1,2]
                 [20, 21], # From context [3,4]
                 [22, 23], # From context [3,4]
             ])
 
         Args:
-            seq: a batch of context (s, a, r, ..., s). Must end with states dataframe token.
-                Shape is (batch_size, context_length).
+            seq: a batch of context ``(s, a, r, ..., s)``. Must end with states dataframe token.
+                Shape is ``(batch_size, context_length)``. If ``context_length`` is greater than
+                :attr:`AutoTokenizer.block_size`, then this input sequence will be silently trimmed
+                to ``(batch_size, block_size)``.
             max_size: Number of samples to return.
             as_token: whether the returned dataframe should be in tokenized format, or in the
                 original value space (approximated).
             correct_unseen_token: Map unseen token to the closest valid token when True.
 
         Returns:
             Whatif dataframe where each row is a sample with actions and rewards columns. The
             ``as_token`` determines whether the dataframe contents are tokenized or in the
             original value space (approximated).
 
-            Shape is (batch_size * max_size, ...). Starting with 1st context's actions, followed
-            2nd context's actions and so on.
+            Shape is ``(batch_size * max_size, ...)``. Starting with the 1st context's actions,
+            followed by the context's actions and so on.
 
         .. note::
-            - Ensure the correct context sequence ``s, a, r, ..., s)`` is passed in.
+            - Ensure the correct context sequence ``(s, a, r, ..., s)`` is passed in.
             - Return ``max_size`` of sampling for each context. Result may not be unique.
             - Each rows of return result represent actions, rewards and values.
 
 
         """
         if not isinstance(seq, np.ndarray):
             raise TypeError(f"seq must be a numpy array, but got {type(seq)}")
```

## a2rl/utils.py

```diff
@@ -515,15 +515,14 @@
 
     # Initial conditions
     state = np.array([[5, 5]])
     T1 = np.array([[0.7, 0.3], [0.6, 0.4]])
     T2 = np.array([[0.5, 0.5], [0.3, 0.7]])
 
     if markov_order == 0:
-
         wi_df = wi.WiDataFrame(
             pd.DataFrame(np.random.randint(0, 100, size=(100, 4)), columns=list("abcd")),
             states=["a", "b"],
             actions=["c"],
             rewards=["d"],
         )
         tokeniser = wi.DiscreteTokenizer(n_bins=50, num_bins_strategy="uniform")
```

## a2rl/mingpt/trainer.py

```diff
@@ -72,27 +72,25 @@
                 batch_size=config.batch_size,
                 num_workers=config.num_workers,
             )
 
             losses = []
             pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)
             for it, (x, y) in pbar:
-
                 # place data on the correct device
                 x = x.to(self.device)
                 y = y.to(self.device)
 
                 # forward the model
                 with torch.set_grad_enabled(is_train):
                     logits, loss = model(x, y)
                     loss = loss.mean()  # collapse all losses if they are scattered on multiple gpus
                     losses.append(loss.item())
 
                 if is_train:
-
                     # backprop and update the parameters
                     model.zero_grad()
                     loss.backward()
                     torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)
                     optimizer.step()
 
                     # decay the learning rate based on our progress
@@ -124,15 +122,14 @@
                 test_loss = float(np.mean(losses))
                 logger.info("test loss: {}", test_loss)
                 return test_loss
 
         best_loss = float("inf")
         self.tokens = 0  # counter used for learning rate decay
         for epoch in range(config.max_epochs):
-
             run_epoch("train")
             if self.test_dataset is not None:
                 test_loss = run_epoch("test")
 
             # supports early stopping based on the test loss, or just save always if no test set is
             # provided
             good_model = self.test_dataset is None or test_loss < best_loss
```

## Comparing `a2rl-1.1.1.dist-info/LICENSE` & `a2rl-1.2.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `a2rl-1.1.1.dist-info/METADATA` & `a2rl-1.2.0.dist-info/METADATA`

 * *Files 11% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: a2rl
-Version: 1.1.1
+Version: 1.2.0
 Summary: Make recommendations for sequential decision problems using offline data
 Home-page: https://github.com/awslabs/amazon-accessible-rl-sdk/
 Download-URL: 
 Author: AWS/ProServe Global Team
 License: Apache License 2.0
 Project-URL: Bug Tracker, https://github.com/awslabs/amazon-accessible-rl-sdk/issues/
 Project-URL: Documentation, https://amazon-accessible-rl-sdk.readthedocs.io/en/stable/
@@ -19,24 +19,25 @@
 License-File: NOTICE
 Requires-Dist: pandas
 Requires-Dist: numpy
 Requires-Dist: scikit-learn
 Requires-Dist: scipy
 Requires-Dist: matplotlib
 Requires-Dist: torch
-Requires-Dist: tqdm (>=4.24.0)
+Requires-Dist: tqdm (>=4.64.1)
 Requires-Dist: PyYaml (>=5.1)
 Requires-Dist: typing-extensions
-Requires-Dist: typeguard
+Requires-Dist: typeguard (>=3.0.0)
 Requires-Dist: nptyping
 Requires-Dist: loguru
 Requires-Dist: gym (<0.26.0,>=0.23.1)
 Requires-Dist: seaborn
 Requires-Dist: cloudpickle
 Requires-Dist: pytorch-lightning (>=1.5.0)
+Requires-Dist: tensorboardX
 Provides-Extra: dev
 Requires-Dist: ipykernel ; extra == 'dev'
 Requires-Dist: pre-commit ; extra == 'dev'
 Requires-Dist: black ; extra == 'dev'
 Requires-Dist: isort ; extra == 'dev'
 Requires-Dist: mypy ; extra == 'dev'
 Requires-Dist: autoflake ; extra == 'dev'
@@ -57,24 +58,29 @@
 Requires-Dist: pytest-lazy-fixture ; extra == 'test'
 Requires-Dist: pytest-console-scripts ; extra == 'test'
 Requires-Dist: pytest-xdist ; extra == 'test'
 
 # Amazon Accessible RL SDK <!-- omit from toc -->
 
 [ [Documentation](https://awslabs.github.io/amazon-accessible-rl-sdk/) |
-[PyPI](https://pypi.org/project/a2rl/) ]
+[PyPI](https://pypi.org/project/a2rl/) |
+[Blog-01](https://medium.com/@yapweiyih/underfloor-heating-optimisation-using-offline-reinforcement-learning-44f7747f4d6f)
+| Blog-02 (coming soon) ]
 
 Amazon Accessible RL (A2RL) is an open-source Python package for [sequential decision making
 problem](https://en.wikipedia.org/wiki/Sequential_decision_making) using offline time-series data.
 It focuses on offline RL using state-of-the-art generative transformer technology – the same
 technology behind [GATO](https://www.deepmind.com/publications/a-generalist-agent), [trajectory
 transformer](https://trajectory-transformer.github.io/) and [decision
 transformer](https://arxiv.org/abs/2106.01345).
 
-A2RL guides you through problem formulation, conduct [initial data
+A2RL guides you through [problem formulation](https://awslabs.github.io/amazon-accessible-rl-sdk/)
+via [data frames
+API](https://awslabs.github.io/amazon-accessible-rl-sdk/example.html#historical-data), conduct
+[initial data
 analysis](https://awslabs.github.io/amazon-accessible-rl-sdk/auto-notebooks/data_properties.html) to
 see if a solution is possible, use the data to train a
 [simulator](https://awslabs.github.io/amazon-accessible-rl-sdk/auto-notebooks/simulator.html) (aka
 *digital twin*) based on the data, and providing [recommended
 actions](https://awslabs.github.io/amazon-accessible-rl-sdk/auto-notebooks/planner_byo_example.html).
 
 ## Installation
@@ -113,11 +119,16 @@
 custom_context = simulator.tokenizer.df_tokenized.sequence[:7]
 recommendation_df = simulator.sample(custom_context, 3)
 
 # Show recommendations (i.e., trajectory)
 recommendation_df
 ```
 
+For more examples, see `notebooks/` (pre-rendered versions
+[here](https://awslabs.github.io/amazon-accessible-rl-sdk/example.html)), and the A2RL blog series:
+[part-1](https://medium.com/@yapweiyih/underfloor-heating-optimisation-using-offline-reinforcement-learning-44f7747f4d6f)
+and part-2 (coming soon).
+
 ## Help and Support
 
 * [Contributing](CONTRIBUTING.md)
 * Apache-2.0 [License](LICENSE)
```

## Comparing `a2rl-1.1.1.dist-info/RECORD` & `a2rl-1.2.0.dist-info/RECORD`

 * *Files 13% similar despite different names*

```diff
@@ -1,30 +1,30 @@
-a2rl/__init__.py,sha256=3QebhQNdyTg6EgGIHkFbcCg1TM0MeFPVVfluypf41Rc,2223
+a2rl/__init__.py,sha256=d0ijg2kFS2X8ClVLGc6X7EoYLWhNsBZXqSkbOyRYuLU,2223
 a2rl/_dataframe.py,sha256=AKPADiIPjprZaW0L-fRN9xFZoi7XX_gjlwlICgmtOZ0,32274
-a2rl/_io.py,sha256=EEKZ4ewKmnwzuh7B9AQAvuS0qOnGNXKD6z1y46sHxhM,13677
+a2rl/_io.py,sha256=_2nlVwNGTh0UgWoMn9KWK41UNZL-fuOoTVYBxviCGKA,13581
 a2rl/_metadatadict.py,sha256=5uVqF0ghh-iw1L2Roz5WPvf64Kh3CBakzvkUG-dYM2w,1304
 a2rl/config.yaml,sha256=bcNrzbcT1UmeHziosWB87wd1HJupRypZgHeV3cdmlPg,154
 a2rl/nbtools.py,sha256=p9jDoyaYBf6MBw7duhaBMvwCK7SvLL3eKFSgA1ORdMk,6413
 a2rl/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-a2rl/simulator.py,sha256=bjFg92RLmd4aqAy5MsehWIwBA2GBN6B34WV-oetA_J8,61786
+a2rl/simulator.py,sha256=V-ZF6MWjYLYefVduTEdasGq884BLqteOKeLvM6xDLAs,67245
 a2rl/tokenizer.py,sha256=_0mt5Pz0-dOX_dQT1GHMXZ-FGpp_THcjJwO5W7tIWpg,19356
-a2rl/utils.py,sha256=IHN03xFFHGuMbE-aoaiyCNw2UEtngzNmn00rRXnt9Ck,19506
+a2rl/utils.py,sha256=OTfHG_p6d6KUFxLex3tSMwM1-tqq9DBkP_2V_hBIHeg,19505
 a2rl/dataset/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 a2rl/dataset/chiller/data.csv,sha256=DueaA7F1Zd0_y4pZHF-fZX00YFx8lIlwt_8WiReiJYg,362007
 a2rl/dataset/chiller/metadata.yaml,sha256=4MzW8V2G9Uoh6_s4I9TWkCOYZAPwX5qgUtuy7yjgAic,178
 a2rl/dataset/rtu/data.csv,sha256=bDHwcgbKha8DhI8CySlzSBLpBJQQkiWZr08v3m9i2pk,228884
 a2rl/dataset/rtu/metadata.yaml,sha256=W5m4Hbr9OCzwcbxVenD8P5YHh03kKNTqWVkZ2S-8910,308
 a2rl/experimental/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 a2rl/experimental/lightgpt/__init__.py,sha256=dAadSpM0KxghjSMrSYMo2FGbxti5mbnou5-6JA9EI8g,651
 a2rl/experimental/lightgpt/config.yaml,sha256=P2xrf-Pd-J7nU1vwLDvhBtXLfDIEs2hiDr3M41u6Ltk,154
 a2rl/experimental/lightgpt/lr_decay.py,sha256=VKj9VzhunPknYHz9VqV99oq9QaOdth3xVYSkB9BVTDI,1711
 a2rl/experimental/lightgpt/model.py,sha256=wO3SQVkts_F0fqnnjIFAJKkT5K_YCzQFrmzdz8u4Y1c,10889
 a2rl/experimental/lightgpt/simulator.py,sha256=ro1hedu-OSV_u9vCEgntT213ZDhiBvXs6PymRYEyd64,6974
 a2rl/mingpt/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 a2rl/mingpt/model.py,sha256=57zDR6rO62lo53E3EawtDRvidXeVZKQ7QIa9KRcfQS8,9458
-a2rl/mingpt/trainer.py,sha256=221K3INE3qP1SRAT18640Uv0lpyBKSu9hnh-_MweZdM,5553
-a2rl-1.1.1.dist-info/LICENSE,sha256=Q_YQWr7ekBlp4gj8pTmrxJz5wWf6F6YwKI-ddoof-Hc,10084
-a2rl-1.1.1.dist-info/METADATA,sha256=9uxkUXm1tXnFq5H-S6bmSn39bQV_V8PFZBkHn6uvK9Q,4792
-a2rl-1.1.1.dist-info/NOTICE,sha256=1CkO1kwu3Q_OHYTj-d-yiBJA_lNN73a4zSntavaD4oc,67
-a2rl-1.1.1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-a2rl-1.1.1.dist-info/top_level.txt,sha256=u5yjN_ZCtHIKVyVcv7hdw4d9UHiu6laOh-xNNQE3okk,5
-a2rl-1.1.1.dist-info/RECORD,,
+a2rl/mingpt/trainer.py,sha256=Zjac94PDG_rQzHMZz_oKoT3RJfuS49AEJJjffAUcokg,5550
+a2rl-1.2.0.dist-info/LICENSE,sha256=Q_YQWr7ekBlp4gj8pTmrxJz5wWf6F6YwKI-ddoof-Hc,10084
+a2rl-1.2.0.dist-info/METADATA,sha256=IV-8LZvvUVVYBxFJCXLQJhMf52_OMjplXMCJpsCcbEk,5445
+a2rl-1.2.0.dist-info/NOTICE,sha256=1CkO1kwu3Q_OHYTj-d-yiBJA_lNN73a4zSntavaD4oc,67
+a2rl-1.2.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+a2rl-1.2.0.dist-info/top_level.txt,sha256=u5yjN_ZCtHIKVyVcv7hdw4d9UHiu6laOh-xNNQE3okk,5
+a2rl-1.2.0.dist-info/RECORD,,
```

