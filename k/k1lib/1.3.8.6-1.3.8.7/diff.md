# Comparing `tmp/k1lib-1.3.8.6-py3-none-any.whl.zip` & `tmp/k1lib-1.3.8.7-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,8 +1,8 @@
-Zip file size: 2541209 bytes, number of entries: 84
+Zip file size: 2542544 bytes, number of entries: 84
 -rw-rw-r--  2.0 unx     1435 b- defN 23-Feb-08 00:13 k1lib/__init__.py
 -rw-rw-r--  2.0 unx    53793 b- defN 23-Apr-02 08:25 k1lib/_baseClasses.py
 -rw-rw-r--  2.0 unx    13494 b- defN 23-May-05 13:41 k1lib/_basics.py
 -rw-rw-r--  2.0 unx     4908 b- defN 23-May-08 18:53 k1lib/_context.py
 -rw-rw-r--  2.0 unx     2866 b- defN 22-Jul-20 04:30 k1lib/_higher.py
 -rw-rw-r--  2.0 unx      948 b- defN 22-Sep-21 23:54 k1lib/_k1a.py
 -rw-rw-r--  2.0 unx    11646 b- defN 23-Jan-14 15:37 k1lib/_learner.py
@@ -43,44 +43,44 @@
 -rw-rw-r--  2.0 unx     3465 b- defN 22-Nov-27 08:16 k1lib/callbacks/lossFunctions/shorts.py
 -rw-rw-r--  2.0 unx       45 b- defN 21-Aug-11 18:19 k1lib/callbacks/profilers/__init__.py
 -rw-rw-r--  2.0 unx     5054 b- defN 22-May-15 09:01 k1lib/callbacks/profilers/computation.py
 -rw-rw-r--  2.0 unx     2319 b- defN 22-May-15 08:59 k1lib/callbacks/profilers/io.py
 -rw-rw-r--  2.0 unx     4419 b- defN 22-May-15 09:00 k1lib/callbacks/profilers/memory.py
 -rw-rw-r--  2.0 unx     4215 b- defN 22-May-15 09:03 k1lib/callbacks/profilers/time.py
 -rw-rw-r--  2.0 unx      925 b- defN 22-Nov-16 09:22 k1lib/cli/__init__.py
--rw-rw-r--  2.0 unx    13717 b- defN 23-May-17 17:15 k1lib/cli/_applyCl.py
+-rw-rw-r--  2.0 unx    15774 b- defN 23-May-19 19:24 k1lib/cli/_applyCl.py
 -rw-rw-r--  2.0 unx     8308 b- defN 22-Nov-27 07:16 k1lib/cli/bio.py
 -rw-rw-r--  2.0 unx     4033 b- defN 23-Jan-25 02:02 k1lib/cli/cif.py
 -rw-rw-r--  2.0 unx    19321 b- defN 23-May-17 19:01 k1lib/cli/conv.py
 -rw-rw-r--  2.0 unx    24071 b- defN 23-May-17 03:12 k1lib/cli/filt.py
 -rw-rw-r--  2.0 unx     6672 b- defN 23-Jan-25 02:02 k1lib/cli/gb.py
 -rw-rw-r--  2.0 unx     6348 b- defN 23-Apr-05 15:10 k1lib/cli/grep.py
 -rw-rw-r--  2.0 unx    18351 b- defN 23-May-12 23:10 k1lib/cli/init.py
--rw-rw-r--  2.0 unx    25961 b- defN 23-May-17 14:30 k1lib/cli/inp.py
+-rw-rw-r--  2.0 unx    25961 b- defN 23-May-22 06:20 k1lib/cli/inp.py
 -rw-rw-r--  2.0 unx      623 b- defN 22-Jun-22 10:43 k1lib/cli/kcsv.py
 -rw-rw-r--  2.0 unx     4819 b- defN 22-Aug-11 20:44 k1lib/cli/kxml.py
 -rw-rw-r--  2.0 unx     1915 b- defN 21-Nov-12 16:48 k1lib/cli/mgi.py
--rw-rw-r--  2.0 unx    60855 b- defN 23-May-17 18:12 k1lib/cli/modifier.py
+-rw-rw-r--  2.0 unx    63021 b- defN 23-May-20 01:45 k1lib/cli/modifier.py
 -rw-rw-r--  2.0 unx      694 b- defN 22-Nov-27 07:17 k1lib/cli/mol.py
 -rw-rw-r--  2.0 unx     4038 b- defN 23-May-09 15:53 k1lib/cli/nb.py
 -rw-rw-r--  2.0 unx     3530 b- defN 22-Aug-16 15:08 k1lib/cli/optimizations.py
 -rw-rw-r--  2.0 unx    11762 b- defN 23-May-16 18:04 k1lib/cli/output.py
 -rw-rw-r--  2.0 unx     2394 b- defN 23-Jan-25 02:03 k1lib/cli/sam.py
--rw-rw-r--  2.0 unx    49930 b- defN 23-May-11 15:29 k1lib/cli/structural.py
+-rw-rw-r--  2.0 unx    49390 b- defN 23-May-19 19:21 k1lib/cli/structural.py
 -rw-rw-r--  2.0 unx    10399 b- defN 22-Aug-05 01:15 k1lib/cli/trace.py
 -rw-rw-r--  2.0 unx    23319 b- defN 22-Sep-29 07:14 k1lib/cli/typehint.py
 -rw-rw-r--  2.0 unx    21101 b- defN 23-May-17 16:57 k1lib/cli/utils.py
 -rw-rw-r--  2.0 unx       20 b- defN 23-Jan-19 22:00 k1lib/k1ui/__init__.py
 -rw-rw-r--  2.0 unx    61803 b- defN 23-Feb-10 12:10 k1lib/k1ui/main.py
 -rw-rw-r--  2.0 unx       20 b- defN 22-Sep-16 01:12 k1lib/serve/__init__.py
 -rw-rw-r--  2.0 unx    10361 b- defN 23-May-05 16:49 k1lib/serve/main.py
 -rw-rw-r--  2.0 unx      153 b- defN 23-May-05 16:00 k1lib/serve/suffix-dash.py
 -rw-rw-r--  2.0 unx      642 b- defN 23-Feb-13 19:00 k1lib/serve/suffix.py
--rw-rw-r--  2.0 unx  2453826 b- defN 23-Jan-19 22:50 k1lib-1.3.8.6.data/data/k1lib/k1ui/256.model.state_dict.pth
--rw-rw-r--  2.0 unx   304735 b- defN 23-Jan-17 19:16 k1lib-1.3.8.6.data/data/k1lib/k1ui/mouseKey.pth
--rw-rw-r--  2.0 unx    20544 b- defN 23-Mar-19 11:14 k1lib-1.3.8.6.data/data/k1lib/serve/main.html
--rw-rw-r--  2.0 unx     1049 b- defN 23-May-17 19:01 k1lib-1.3.8.6.dist-info/LICENSE
--rw-rw-r--  2.0 unx     3864 b- defN 23-May-17 19:01 k1lib-1.3.8.6.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-May-17 19:01 k1lib-1.3.8.6.dist-info/WHEEL
--rw-rw-r--  2.0 unx        6 b- defN 23-May-17 19:01 k1lib-1.3.8.6.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     6704 b- defN 23-May-17 19:01 k1lib-1.3.8.6.dist-info/RECORD
-84 files, 3510161 bytes uncompressed, 2530869 bytes compressed:  27.9%
+-rw-rw-r--  2.0 unx  2453826 b- defN 23-Jan-19 22:50 k1lib-1.3.8.7.data/data/k1lib/k1ui/256.model.state_dict.pth
+-rw-rw-r--  2.0 unx   304735 b- defN 23-Jan-17 19:16 k1lib-1.3.8.7.data/data/k1lib/k1ui/mouseKey.pth
+-rw-rw-r--  2.0 unx    20544 b- defN 23-Mar-19 11:14 k1lib-1.3.8.7.data/data/k1lib/serve/main.html
+-rw-rw-r--  2.0 unx     1049 b- defN 23-May-22 06:21 k1lib-1.3.8.7.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     3864 b- defN 23-May-22 06:21 k1lib-1.3.8.7.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-May-22 06:21 k1lib-1.3.8.7.dist-info/WHEEL
+-rw-rw-r--  2.0 unx        6 b- defN 23-May-22 06:21 k1lib-1.3.8.7.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     6704 b- defN 23-May-22 06:21 k1lib-1.3.8.7.dist-info/RECORD
+84 files, 3513844 bytes uncompressed, 2532204 bytes compressed:  27.9%
```

## zipnote {}

```diff
@@ -222,32 +222,32 @@
 
 Filename: k1lib/serve/suffix-dash.py
 Comment: 
 
 Filename: k1lib/serve/suffix.py
 Comment: 
 
-Filename: k1lib-1.3.8.6.data/data/k1lib/k1ui/256.model.state_dict.pth
+Filename: k1lib-1.3.8.7.data/data/k1lib/k1ui/256.model.state_dict.pth
 Comment: 
 
-Filename: k1lib-1.3.8.6.data/data/k1lib/k1ui/mouseKey.pth
+Filename: k1lib-1.3.8.7.data/data/k1lib/k1ui/mouseKey.pth
 Comment: 
 
-Filename: k1lib-1.3.8.6.data/data/k1lib/serve/main.html
+Filename: k1lib-1.3.8.7.data/data/k1lib/serve/main.html
 Comment: 
 
-Filename: k1lib-1.3.8.6.dist-info/LICENSE
+Filename: k1lib-1.3.8.7.dist-info/LICENSE
 Comment: 
 
-Filename: k1lib-1.3.8.6.dist-info/METADATA
+Filename: k1lib-1.3.8.7.dist-info/METADATA
 Comment: 
 
-Filename: k1lib-1.3.8.6.dist-info/WHEEL
+Filename: k1lib-1.3.8.7.dist-info/WHEEL
 Comment: 
 
-Filename: k1lib-1.3.8.6.dist-info/top_level.txt
+Filename: k1lib-1.3.8.7.dist-info/top_level.txt
 Comment: 
 
-Filename: k1lib-1.3.8.6.dist-info/RECORD
+Filename: k1lib-1.3.8.7.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## k1lib/cli/_applyCl.py

```diff
@@ -1,12 +1,12 @@
 # AUTOGENERATED FILE! PLEASE DON'T EDIT
 from k1lib.imports import *
 getFolderSize = ls() | filt(os.path.isdir).split() | apply(lambda x: x | (tryout(0) | getFolderSize)) + apply(os.path.getsize) | toSum().all() | toSum() | deref()
-getFilesInFolder = aS(os.walk) | cut(0, 2) | ungroup(True, True) | join(os.sep).all()
-def getIr(base): return None | applyCl.aS(lambda: ls(base) | iden() & apply(lambda x: x | (tryout(0) | (aS(os.path.getsize) if os.path.isfile(x) else getFolderSize))) | transpose() | deref()) | ungroup(begin=True) | insertIdColumn(True) | deref()
+getFilesInFolder = aS(os.walk) | cut(0, 2) | ungroup() | join(os.sep).all()
+def getIr(base): return None | applyCl.aS(lambda: ls(base) | iden() & apply(lambda x: x | (tryout(0) | (aS(os.path.getsize) if os.path.isfile(x) else getFolderSize))) | transpose() | deref()) | ungroup(False) | insertIdColumn(True) | deref()
 def normalize(d):
     d = d | deref(); s = d | cut(1) | toSum()
     return d | apply(op()/s, 1) | sort(0, False) | deref()
 @lru_cache
 def statsCpu():
     cpu = None | applyCl.aS(applyCl.cpu) | sort(0, False) | deref()
     cpuF = None | applyCl.aS(applyCl.cpu) | aS(normalize); cpuF # "cpuF" = cpu fraction. List[nodeId, cpu fraction]
@@ -100,28 +100,28 @@
     applyCl.cmd(f"rm -rf {folder}"); applyCl.cmd(f"mkdir -p {folder}"); size = getSize(url)
     cpus = None | applyCl.aS(lambda: applyCl.cpu()) | deref(); n = cpus | cut(1) | toSum()
     tasks = [cpus | ~apply(lambda x,y: [x]*y) | joinStreams(), range(size) | splitW(*[1]*n)] | transpose() | insertIdColumn(True, False) | ~apply(lambda x,y,z: [x,[y,f"{folder}/{z}.bin"]]) | deref(1)
     tasks | ~applyCl(lambda r, fn: getChunks(url, r.start, r.stop-1, None, chunkTimeout) | file(fn), pre=True, timeout=timeout) | deref()
     if merge:
         None | cmd(f"rm -rf {destFile}") | deref()
         None | cmd(f"mkdir -p {dirname}") | deref()
-        None | applyCl.aS(lambda: ls(folder)) | ungroup(True, True) | deref() | sortF(op().split(".bin")[0].split("/")[-1].ab_int(), 1) | applyCl(cat(text=False), pre=True) | cut(1) | file(destFile)
+        None | applyCl.aS(lambda: ls(folder)) | ungroup() | deref() | sortF(op().split(".bin")[0].split("/")[-1].ab_int(), 1) | applyCl(cat(text=False), pre=True) | cut(1) | file(destFile)
         None | cmd(f"rm -rf {folder}") | deref()
 def a_transfer(fn, nse, nodeB, rpF:callable=iden()):
     """Transfers a lot of blocks from a bunch of nodes to nodeB. Does not delete from those node though
 
 nse = List[nodeAId, [sB, eB]]
 
 Runs on driver process, blocks, so better use applyTh outside of this
 
 :param rpF: ray progress function"""
     blockSize = settings.cli.cat.chunkSize
     def inner():
         totalBytes = nse | cut(1) | ~apply(lambda x,y:y-x) | toSum(); currentByte = 0
-        for chunk in nse | ~apply(lambda x, y: range(x, y) | batched(blockSize, True) | apply("[x.start, x.stop]"), 1) | ungroup(True, True) | deref()\
+        for chunk in nse | ~apply(lambda x, y: range(x, y) | batched(blockSize, True) | apply("[x.start, x.stop]"), 1) | ungroup() | deref()\
             | ~applyCl(lambda sB, eB: cat(fn, False, sB=sB, eB=eB), pre=True, timeout=None, prefetch=20) | cut(1):
             chunk >> file(fn); currentByte += len(chunk); rpF(currentByte/totalBytes)
     [nodeB] | applyCl.aS(inner, timeout=None) | item()
 def decommission(fn:str, nodeAs:List[str], nodeBs:List[str], rS=iden()):
     """Spreads out a particular file in nodeAs to all nodeBs, to prepare
 to decomission nodeAs. The 2 sets should be mutually exclusive
 
@@ -153,35 +153,47 @@
     ns = [*nAs, *nBs]; totalCpu = ns | lookup(nodeId2Cpu) | toSum(); bytePerCpu = totalSize/totalCpu; wsB = nBs | lookup(nodeId2Cpu) | deref()
     # prepares segments and metadata, List[nodeId, [sB, eB]], where sB and eB are the ranges of nAs that they're willing to share
     sizePost = sizes | ~apply(lambda idx, size: [idx, nodeId2Cpu[idx]/totalCpu*totalSize/size]) | deref()
     invalidNodes = sizePost | ~filt(lambda x: 0 <= x <= 1, 1) | cut(0) | deref()
     if len(invalidNodes) > 0: raise Exception(f"Unsupported configuration! These nodes have too little data to share: {invalidNodes}. This couldn't have happen using applyCl alone. Data is not corrupted, but you'll have to combine data from all files into 1 and spread them back out again.")
     inter = sizePost | ~apply(lambda idx, x: [idx, [x, 1-x]]) | applyCl(lambda ws: fn | splitSeek(ws=ws) | rS | ~head(1), pre=True) | deref() | filt(~aS(lambda x,y: y-x>0), 1) | deref()
     # actually transferring data to new nodes
-    meta = inter | apply(~aS(range) | splitW(*wsB) | rS | apply(wrapList()) | insertColumn(nBs) | deref(1), 1) | ungroup(begin=True) | apply("[x.start, x.stop]", 2) | groupBy(1, True) | deref()
+    meta = inter | apply(~aS(range) | splitW(*wsB) | rS | apply(wrapList()) | insertColumn(nBs) | deref(1), 1) | ungroup(False) | apply("[x.start, x.stop]", 2) | groupBy(1, True) | deref()
     with ray.progress(len(meta), "Transferring data to new nodes") as rp:
         meta | insertIdColumn(True) | applyTh(~aS(lambda idx, nB, nse: a_transfer(fn, nse, nB, rpF=aS(lambda p: ray.get(rp.update.remote(idx, p))))), timeout=None) | deref()
     # truncates the files in nAs nodes
     inter | ~apply(lambda idx,se: [idx,se[0]]) | applyCl(lambda sB: open(fn, 'a').truncate(sB), pre=True, timeout=None) | deref()
 def balanceFile(fn:str, nAs:List[str]=None, nBs:List[str]=None, rS=iden()):
     fn = os.path.expanduser(fn)
     if nAs is None: nAs = None | applyCl.aS(lambda: os.path.exists(fn)) | filt(op(), 1) | cut(0) | deref()
     if nBs is None: nBs = applyCl.nodeIds()
     decommission(fn, *nAs | inSet(nBs).split() | reverse(), rS)
     spreadOut(fn, *nBs | inSet(nAs).split(), rS)
-def diskScan1(base:str) -> List[str]:
+def diskScan1(base:str) -> List[str]: # like ls(), but returns files and folders that appear at least on 2 nodes
     isdir, base = base.split("\ue000")
     if not isdir: return []
     return None | applyCl.aS(lambda: base | (tryout([]) | ls() | apply(os.path.isdir) & iden() | transpose() | ~apply(lambda x,y: f"{x*1}\ue000{y}")) | deref()) | cut(1) | joinStreams() | count() | filt(op()>1, 0) | cut(1) | deref()
 def diskScan2(base:str) -> Tuple[List[str], List[str]]: # returns list of distributed folders and list of distributed files
     dFolders = []; folders, files = diskScan1(base) | op().split("\ue000").all() | toInt(0) | filt(op(), 0).split() | (join("\ue000")).all(2) | deref()
+    # print("2--", folders, files, base)
     for folder in folders:
-        fol, fil = diskScan2(folder)
-        if len(fol) + len(fil) == 0: dFolders.append(folder)
+        fol, fil = diskScan2(folder); dFolders.extend(fol); files.extend(fil)
+        if len(fol) + len(fil) == 0: dFolders.append(folder) # no shared contents, must be a distributed folder
         else: files.extend(fil)
+    # print("3--", [dFolders, files], base)
     return [dFolders, files]
 def diskScan3(base:str): base = os.path.expanduser(base); return diskScan2(f"1\ue000{base}") | op().split("\ue000")[1].all(2) | deref()
-def diskScan4(base:str):
+def diskScan4(base:str, sortSize=True): # fully featured data
     folders, files = diskScan3(base)
     folders = [folders, None | applyCl.aS(lambda: folders | apply(lambda x: (x | getFolderSize) if os.path.exists(x) else 0) | deref()) | cut(1) | transpose()] | transpose() | deref()
     files   = [files,   None | applyCl.aS(lambda: files   | apply(lambda x: os.path.getsize(x)  if os.path.exists(x) else 0) | deref()) | cut(1) | transpose()] | transpose() | deref()
-    return [folders, files]
+    post = apply(~sortF(toSum(), 1)) if sortSize else iden()
+    return [folders, files] | wrapList() + filt(filt(op() > 0) | count() | shape(0) | (op() == 1), 1).split() | joinStreams() | apply(unique(0)) | post | deref()
+def diskScan5(base:str, sortSize=True): # displays it in a nice format
+    d4 = diskScan4(base, sortSize); nodeNames = None | applyCl.aS(lambda: applyCl.cpu()) | apply(op()[:5], 0) | apply('f"{x} thr"', 1) | join(", ").all() | deref(); nodeNames
+    d5 = d4 | apply(~apply(lambda path, sizes: [path, sizes | toSum() | aS(fmt.size), sizes | apply(fmt.size)]) | insert(["-"*40, "-"*10, ["-"*12]*len(nodeNames)]) | insert(["", "", nodeNames])) | deref(); d5
+    ws = d5 | shape(0).all() | deref()
+    d6 = d5 | joinStreams() | cut(0, 1) & (cut(2) | pretty() | wrapList().all()) | transpose() | joinStreams().all() | splitW(*ws) | insert(["Path", "Total size", "Size on each node (node id and thread count)"]).all() | joinStreams() | pretty() | splitW(*ws | apply(op()+1)) | deref()
+    explainers = ["\nA distributed folder is a folder that has many files and folders inside, but their names\nare all different from each other. It's managed by applyCl.balanceFolder()",
+                  "\nA replicated file is a file that has been copied to multiple nodes. Size of all file\ncopies should be the same. It's managed by applyCl.replicateFile()",
+                  "\nA distributed file is a file that has been split into multiple pieces and sent to other\nnodes. It's managed by applyCl.balanceFile()"]
+    [d6, ["Distributed folders", "Replicated files", "Distributed files"] | (aS(lambda x: [["-"*60, x, "-"*60] | join(" ")])).all()] | transpose() | permute(1, 0) | (joinStreams() | join("\n")).all() | wrapList() | insert(explainers, False) | transpose() | join("\n").all() | join("\n"*2) | wrapList() | stdout()
```

## k1lib/cli/modifier.py

```diff
@@ -368,14 +368,21 @@
         return
         if hasattr(self, "p"):
             self.p.terminate();
             if self.p in applyMp._pools: applyMp._pools.remove(self.p)
 # apparently, this doesn't do anything, at least in jupyter environment
 atexit.register(lambda: applyMp.clearPools())
 parallel = applyMp
+s = k1lib.Settings(); settings.add("applyCl", s, "modifier.applyCl() settings")
+s.add("sudoTimeout", 300, "seconds before deleting the stored password for sudo commands")
+_password = k1lib.Wrapper(None)
+def removePw():
+    while True: time.sleep(settings.applyCl.sudoTimeout); _password.value = None
+t = threading.Thread(target=removePw, daemon=True).start()
+_nodeIdsCache = k1lib.Wrapper([])
 def specificNode(obj, nodeId:str):
     return obj.options(scheduling_strategy=ray.util.scheduling_strategies.NodeAffinitySchedulingStrategy(node_id=nodeId, soft=False))
 class applyCl(BaseCli):
     def __init__(self, f, prefetch=None, timeout=60, bs=1, rss:Union[dict, str]={}, pre:bool=False, orPatch=True, num_cpus=1, **kwargs):
         """Like :class:`apply`, but execute a function over the input iterator
 in multiple processes on multiple nodes inside of a cluster (hence "cl"). So, just a more
 powerful version of :class:`applyMp`, assuming you have a cluster to run it on.
@@ -413,15 +420,15 @@
 .. admonition:: Advanced use case
 
     Not really advanced, but just a bit difficult to understand/follow. Let's say
     that you want to scan through the home directory of all nodes, grab all files,
     read them, and get the number of bytes they have. You can do something like this::
     
         a = None | applyCl.aS(lambda: None | cmd("ls ~") | filt(os.path.isfile) | deref()) | deref()
-        b = a | ungroup(single=True, begin=True) | deref()
+        b = a | ungroup() | deref()
         c = b | applyCl(cat(text=False) | shape(0), pre=True) | deref()
         d = c | groupBy(0, True) | apply(item().all() | toSum(), 1) | deref()
     
     Noted, this is relatively complex. Let's see what A, B, C and D looks like::
     
         # A
         [['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', ['Miniconda3-latest-Linux-x86_64.sh', 'mintupgrade-2023-04-01T232950.log']],
@@ -541,25 +548,41 @@
 f is executed once, hence the name "apply Single". Here, the meaning of "single" is
 different. It just means execute once for each node ids.
 
 :param f: main function to execute in each node. Not supposed to accept any arguments
 :param timeout: seconds to wait for job before raising an error"""
         f = fastF(f); g = lambda nodeId: specificNode(ray.remote(f), nodeId).remote()
         final = cli.iden() & (apply(g) | aS(list) | apply(ray.get, timeout=timeout)) | cli.transpose()
-        return aS(lambda it: (applyCl.nodeIds() if it is None else it) | final)
+        def inner(it):
+            if it is None: it = applyCl.nodeIds()
+            else:
+                if it | ~cli.inSet(_nodeIdsCache()) | cli.shape(0) > 0:
+                    _nodeIdsCache.value = applyCl.nodeIds(); outliers = it | ~cli.inSet(_nodeIdsCache()) | cli.deref()
+                    if len(outliers) > 0: raise Exception(f"These nodes cannot be found: {outliers}")
+            return it | final
+        return aS(inner)
     @staticmethod
-    def cmd(s:str, timeout:float=8):
+    def cmd(s:str, timeout:float=8, sudo=False):
         """Convenience function to execute shell command on all nodes.
 Example::
 
     applyCl.cmd("mkdir -p /some/folder")
 
 It returns [[nodeid1, output1], [nodeid2, output2]]. If you need more flexibility,
-fall back to :meth:`applyCl.aS`"""
-        return None | applyCl.aS(lambda: None | cli.cmd(s) | cli.deref(), timeout) | cli.deref()
+fall back to :meth:`applyCl.aS`
+
+:param s: shell command to execute
+:param sudo: if True, will execute the command with sudo privileges. Will ask for password
+    and then cache it internally for 5 minutes"""
+        global _password; import getpass
+        if sudo:
+            if _password() is None:
+                print("Enter password:"); _password.value = getpass.getpass(prompt="")
+            return   None | applyCl.aS(lambda: _password() | cli.cmd(f"sudo -S {s}") | cli.deref(), timeout) | cli.deref()
+        else: return None | applyCl.aS(lambda: None        | cli.cmd(s)              | cli.deref(), timeout) | cli.deref()
     @staticmethod
     def replicateFile(fn:str, nodeIds=None):
         """Replicates a specific file in the current node to all the other nodes.
 Example::
 
     applyCl.replicate("~/cron.log")
 
@@ -700,15 +723,15 @@
     dir_ = "~/repos/labs/k1lib/k1lib/cli/test"
     fn = f"{dir_}/applyCl.cat.data"
     applyCl.cmd(f"rm -r {dir_}/applyCl")    # clear out old folders
     applyCl.cmd(f"mkdir -p {dir_}/applyCl") # creating folders
     # do processing on fn distributedly, then dump results into multiple files
     applyCl.cat(fn, ~aS(lambda idx, lines: lines | shape(0) | aS(dill.dumps) | file(f"{dir_}/applyCl/{idx}.pth")), includeId=True) | deref()
     # reading all files and summing them together
-    None | applyCl.aS(lambda: ls(f"{dir_}/applyCl")) | ungroup(single=True, begin=True) | applyCl(cat(text=False) | aS(dill.loads), pre=True) | cut(1) | toSum()
+    None | applyCl.aS(lambda: ls(f"{dir_}/applyCl")) | ungroup() | applyCl(cat(text=False) | aS(dill.loads), pre=True) | cut(1) | toSum()
 
 .. admonition:: Simple mode
 
     There's also another mode that's activated whenever f is not specified that feels
     more like vanilla :class:`~inp.cat`. Say you have a file on a specific node::
     
         nodeId = "7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d"
@@ -742,15 +765,15 @@
                 inter = seeks | cli.window(2) | apply(cli.wrapList() | cli.insert(nodeId)) | cli.deref()
                 return inter | ~applyCl(lambda sB, eB: cli.cat(fn,sB=sB,eB=eB) | cli.deref(), pre=True) | cli.cut(1) | cli.joinStreams()
                 # return [nodeId_fn] | applyCl(cat() | deref(), pre=True) | cut(1) | item() # direct, no chunking method
             if fn is None: return aS(inner) # [nodeId, fn] | applyCl.cat()
             if isinstance(fn, str): return aS(lambda nodeId: inner([nodeId, fn])) # nodeId | applyCl.cat()
             else: return inner(fn) # applyCl.cat([nodeId, fn])
         postprocess = cli.insertIdColumn(True, False) | ~apply(lambda x,y,z: [x,[*y,z]])
-        checkpoints = None | applyCl.aS(lambda: fn | cli.splitSeek(int(applyCl.meta()["Resources"]["CPU"]*multiplier)) | cli.window(2) | cli.deref()) | cli.ungroup(single=True, begin=True) | postprocess | cli.deref()
+        checkpoints = None | applyCl.aS(lambda: fn | cli.splitSeek(int(applyCl.meta()["Resources"]["CPU"]*multiplier)) | cli.window(2) | cli.deref()) | cli.ungroup() | postprocess | cli.deref()
         postprocess = cli.iden() if keepNodeIds else cli.cut(1)
         return checkpoints | applyCl(~aS(lambda x,y,idx: cli.cat(fn, sB=x, eB=y) | ((cli.wrapList() | cli.insert(idx)) if includeId else cli.iden()) | f), pre=True, timeout=timeout, num_cpus=1) | postprocess
     @staticmethod
     def balanceFolder(folder:str, maxSteps:int=None, audit:bool=False):
         """Balances all files within a folder across all nodes.
 Example::
 
@@ -774,16 +797,16 @@
 So imagine that you just downloaded 1000 files to a single node on a specific folder,
 but you need to analyze all of them in a distributed manner. What you can do is to
 move some files to other nodes and then do your analysis. If you want to download
 more files, just dump it to any node (or download distributed across all nodes),
 then rebalance the folders and do your analysis.
 
 :param folder: folder to rebalance all of the files
-:param audit: if True, don't actually move files around and just return what files are going to be moved where
-:param maxSteps: what's the maximum number of file transfers?"""
+:param maxSteps: what's the maximum number of file transfers? By default has no limit, so that files are transferred until 
+:param audit: if True, don't actually move files around and just return what files are going to be moved where"""
         from k1lib.cli._applyCl import balanceFolder
         return balanceFolder(folder, audit, maxSteps)
     def download(url:str, folder:str, merge:bool=False, timeout=120, chunkTimeout=5):
         """Downloads a file distributedly to a specified folder.
 Example::
 
     url = "https://vim.kelvinho.org"
@@ -797,69 +820,75 @@
 :param folder: which folder to download parts into
 :param merge: whether to merge all of the fragments together into a single file in the current node or not
 :param timeout: timeout for each process
 :param chunkTimeout: timeout for each file chunk inside each process"""
         from k1lib.cli._applyCl import download
         download(url, folder, merge, timeout, chunkTimeout)
     @staticmethod
-    def diskScan(folder:str, size=False):
+    def diskScan(folder:str, raw=False):
         """Scans for files and folders in the specified folder for potential
 distributed files and folders. A distributed file is a file that exists on more
 than 1 node. A distributed folder is a folder that that exists on more than 1
 node and does not have any shared children. Example::
 
     applyCl.diskScan("~/ssd2")
     applyCl.diskScan("~/ssd2", True)
 
-Those 2 lines return these respective outputs::
+The first line does not return anything, but will print out something like this:
+
+.. include:: ../literals/diskScan.rst
 
-    [['/home/kelvin/ssd2/test'],
-     ['/home/kelvin/ssd2/data/genome/00-common_all.vcf',
-      '/home/kelvin/ssd2/data/genome/00-All.vcf',
-      '/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff']]
-
-    [[['/home/kelvin/ssd2/test', [136152, 273530, 136351]]],
-     [['/home/kelvin/ssd2/data/genome/00-common_all.vcf', [2353901811, 4707803470, 2353901831]],
-      ['/home/kelvin/ssd2/data/genome/00-All.vcf', [32737509360, 65475018903, 32737509588]],
-      ['/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff', [13963854962, 27927709895, 13963854962]]]]
+While the second line will return a parseable data structure instead::
+
+    [[['/home/kelvin/ssd2/data/genome/RegulationFeatureActivity', [4113489746, 7912834090, 4164314316]],
+      ['/home/kelvin/ssd2/data/genome/go/release_geneontology_org', [2071645117, 4172737915, 2107005131]],
+      ['/home/kelvin/ssd2/data/genome/RegulationFeatureActivity.backup', [568878496, 552888466, 600610083]],
+      ['/home/kelvin/ssd2/data/genome/00-common_all.idx', [341738564, 671136833, 0]],
+      ['/home/kelvin/ssd2/data/genome/genbank/ch1.dat.gz', [25356744, 0, 25356764]],
+      ['/home/kelvin/ssd2/test', [136152, 273530, 136351]],
+      ['/home/kelvin/ssd2/data/genome/genbank/ch1', [0, 0, 0]]],
+     [['/home/kelvin/ssd2/data/genome/dummy.txt', [1101, 1101, 1101]]],
+     [['/home/kelvin/ssd2/data/genome/00-All.vcf', [32737509360, 65475018903, 32737509588]],
+      ['/home/kelvin/ssd2/data/genome/MotifFeatures/homo_sapiens.GRCh38.motif_features.gff', [13963854962, 27927709895, 13963854962]],
+      ['/home/kelvin/ssd2/data/genome/00-common_all.vcf', [2353901811, 4707803470, 2353901831]]]]
 
 Remember that since an operating system usually have lots of shared files
 (like "~/.bashrc", for example), these might be mistaken as a distributed file.
-Make sure to only scan folders that you store data in.
+Make sure to only scan folders that you store data in, or else it'll take a long time to return.
 
 :param folder: the folder to scan through
-:param size: whether to include folder/file size on each respective nodes"""
-        from k1lib.cli._applyCl import diskScan3, diskScan4
-        if size: return diskScan4(folder)
-        else: return diskScan3(folder)
+:param raw: whether to return raw data or display it out nicely"""
+        from k1lib.cli._applyCl import diskScan4, diskScan5
+        if raw: return diskScan4(folder)
+        else: return diskScan5(folder)
 thEmptySentinel = object()
 class applyTh(BaseCli):
-    def __init__(self, f, prefetch:int=None, timeout:float=5, bs:int=1):
+    def __init__(self, f, prefetch:int=None, timeout:float=5, bs:int=1, **kwargs):
         """Kinda like the same as :class:`applyMp`, but executes ``f`` on multiple
 threads, instead of on multiple processes. Advantages:
 
 - Relatively low overhead for thread creation
 - Fast, if ``f`` is io-bound
 - Does not have to serialize and deserialize the result, meaning iterators can be
   exchanged
 
 Disadvantages:
 
 - Still has thread creation overhead, so it's still recommended to specify ``bs``
 - Is slow if ``f`` has to obtain the GIL to be able to do anything
 
 All examples from :class:`applyMp` should work perfectly here."""
-        fs = [f]; super().__init__(fs=fs); self.f = fs[0]; self.bs = bs
+        fs = [f]; super().__init__(fs=fs); self.f = fs[0]; self.bs = bs; self.kwargs = kwargs
         self.prefetch = prefetch or int(1e9); self.timeout = timeout
     def __ror__(self, it):
         if self.bs > 1:
             yield from (it | cli.batched(self.bs, True) | applyTh(apply(self.f), self.prefetch, self.timeout) | cli.joinStreams()); return
-        datas = deque(); it = iter(it)
+        datas = deque(); it = iter(it); kwargs = self.kwargs
         innerF = fastF(self.f); timeout = self.timeout
-        def f(line, wrapper): wrapper.value = innerF(line)
+        def f(line, wrapper): wrapper.value = innerF(line, **kwargs)
         for _, line in zip(range(self.prefetch), it):
             w = k1lib.Wrapper(thEmptySentinel)
             t = threading.Thread(target=f, args=(line,w))
             t.start(); datas.append((t, w))
         for line in it:
             data = datas.popleft(); data[0].join(timeout)
             if data[1].value is thEmptySentinel:
@@ -870,14 +899,21 @@
             t.start(); datas.append((t, w))
         for i in range(len(datas)): # do it this way so that python can remove threads early, due to ref counting
             data = datas.popleft(); data[0].join(timeout)
             if data[1].value is thEmptySentinel:
                 for data in datas: data[0].join(0.01)
                 raise RuntimeError("Thread timed out!")
             yield data[1].value
+    def _copy(self): return applyTh(self.f, self.prefetch, self.timeout, self.bs, **self.kwargs)
+    def __invert__(self):
+        res = self._copy(); f = fastF(res.f)
+        kw = res.kwargs
+        res.f = lambda x: f(*x, **kw)
+        res.kwargs = {}
+        return res
 class applySerial(BaseCli):
     def __init__(self, f, *args, **kwargs):
         """Applies a function repeatedly. First yields input iterator ``x``. Then
 yields ``f(x)``, then ``f(f(x))``, then ``f(f(f(x)))`` and so on. Example::
 
     # returns [2, 4, 8, 16, 32]
     2 | applySerial(op()*2) | head(5) | deref()
```

## k1lib/cli/structural.py

```diff
@@ -560,45 +560,25 @@
                     a = [e]; v = a[0][c]
         except StopIteration:
             if len(a) > 0:
                 if removeCol: a = a | ~cli.cut(c)
                 if separate: yield [v, a]
                 else: yield a
 class ungroup(BaseCli):
-    def __init__(self, single=False, begin=False, insertCol:bool=True):
+    def __init__(self, single=True, begin=True, insertCol:bool=True):
         """Ungroups things that were grouped using a specific mode of
 :class:`groupBy`. Particularly useful to transform some complex data
 structure into a flat dataframe so that you can plug into pandas. Example::
 
-    a = [[2.3, 5], [3.4, 2], [4.5, 2], [5.6, 5], [6.7, 1]]
-    # returns [[6.7, 1], [3.4, 2], [4.5, 2], [2.3, 5], [5.6, 5]]
-    a | groupBy(1, True) | ungroup() | deref()
-    # returns [[6.7], [3.4], [4.5], [2.3], [5.6]]
-    a | groupBy(1, True) | ungroup(False) | deref()
-
-Just as a reminder, this is the output of :class:`groupBy` after executing ``a | groupBy(1, True)``::
-
-    [[1, [[6.7]]],
-     [2, [[3.4], [4.5]]],
-     [5, [[2.3], [5.6]]]]
-
-A lot of times, your data is a little bit different, like this perhaps::
-
-    [[1, [6.7]],
-     [2, [3.4, 4.5]],
-     [5, [2.3, 5.6]]]
-
-A way to fix this would be to add ``apply(wrapList().all(), 1)`` before :class:`ungroup`.
-But because this is so common, I've added in the parameter ``single`` for that. Just set
-it to True::
-
-    # returns [[6.7, 1], [3.4, 2], [4.5, 2], [2.3, 5], [5.6, 5]]
-    [[1, [6.7]],
-     [2, [3.4, 4.5]],
-     [5, [2.3, 5.6]]] | ungroup(single=True)
+    # returns [[3, 1.2], [3, 3.4], [5, 6], [5, 8], [5, 11]]
+    [[3, [1.2, 3.4]], [5, [6, 8, 11]]] | ungroup() | deref()
+    # returns [[3, 1.2], [3, 3.4], [5, 6], [5, 8], [5, 11]]
+    [[3, [[1.2], [3.4]]], [5, [[6], [8], [11]]]] | ungroup(False) | deref()
+    # returns [[1.2, 3], [3.4, 3], [6, 5], [8, 5], [11, 5]]
+    [[3, [1.2, 3.4]], [5, [6, 8, 11]]] | ungroup(begin=False) | deref()
 
 :param single: whether the table in each group has a single column or not
 :param begin: whether to insert the column at the beginning or at the end.
     Only works if ``insertCol`` is True
 :param insertCol: whether to insert the column into the table or not"""
         self.insertCol = insertCol; self.single = single; self.begin = begin
     def __ror__(self, it):
```

## Comparing `k1lib-1.3.8.6.data/data/k1lib/k1ui/256.model.state_dict.pth` & `k1lib-1.3.8.7.data/data/k1lib/k1ui/256.model.state_dict.pth`

 * *Files identical despite different names*

## Comparing `k1lib-1.3.8.6.data/data/k1lib/k1ui/mouseKey.pth` & `k1lib-1.3.8.7.data/data/k1lib/k1ui/mouseKey.pth`

 * *Files identical despite different names*

## Comparing `k1lib-1.3.8.6.data/data/k1lib/serve/main.html` & `k1lib-1.3.8.7.data/data/k1lib/serve/main.html`

 * *Files identical despite different names*

## Comparing `k1lib-1.3.8.6.dist-info/LICENSE` & `k1lib-1.3.8.7.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `k1lib-1.3.8.6.dist-info/METADATA` & `k1lib-1.3.8.7.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: k1lib
-Version: 1.3.8.6
+Version: 1.3.8.7
 Summary: Some nice ML overhaul
 Home-page: https://k1lib.com
 Author: Quang Ho
 Author-email: 157239q@gmail.com
 License: MIT
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown
```

## Comparing `k1lib-1.3.8.6.dist-info/RECORD` & `k1lib-1.3.8.7.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -42,43 +42,43 @@
 k1lib/callbacks/lossFunctions/shorts.py,sha256=wXeUSgGDIdu_nsiAvn4pKs3fQrcO2FwpNXKcBCFvGzY,3465
 k1lib/callbacks/profilers/__init__.py,sha256=Gp5IvLRABYAg1J0ilTT2v72gfDbyTvUUHUEpvlSo1Lc,45
 k1lib/callbacks/profilers/computation.py,sha256=gPNsoioghh4PI5w8s2p8qYOrR7XObslqCLH5EkNOPSI,5054
 k1lib/callbacks/profilers/io.py,sha256=H8E0YzmLWRD9T2_RyDG2eXvbQQnJgzEnEyx8PqfQ4wY,2319
 k1lib/callbacks/profilers/memory.py,sha256=L0F5pc5LB0dtSnRot8ReR-amZn1uIXv0py0XmGS166U,4419
 k1lib/callbacks/profilers/time.py,sha256=R2-2ZooDwLQIeyonLp2Zz5E_uXzdy6mWUgw6uavQbpE,4215
 k1lib/cli/__init__.py,sha256=hF0ODhL20OSM9o1j68VhcIVflibgSpPuqeyYlsh8oow,925
-k1lib/cli/_applyCl.py,sha256=NeORAWaBsBWQ_XG5fxwaeJAN5QuMMfzCu7STN-r4SCA,13717
+k1lib/cli/_applyCl.py,sha256=tq-2axIX-KM-ZCR8z3eqL5amSbPNg3HvR-Y6pJuzyw8,15774
 k1lib/cli/bio.py,sha256=PhGvy-fDA-wrUzzEDpuRe4x-Kbylx0sNmoXCEZfE_FA,8308
 k1lib/cli/cif.py,sha256=77FX83m1FRYEeZkdXJ8MiVapqCSzZ-1xOQ8ZLeHfhf8,4033
 k1lib/cli/conv.py,sha256=KcwSs9mD54XA5BC7ajxPF_1CZsu54i6dH6DtEv_fbv0,19321
 k1lib/cli/filt.py,sha256=c-bueTrH_5KAgRTtNiK4t4jfCy6xu-d0rYEUVF9KKGA,24071
 k1lib/cli/gb.py,sha256=xxjuNYgWrrElRckon3gP0sj-dShYnKs3jmHAb1U0kVI,6672
 k1lib/cli/grep.py,sha256=Lu4PFOe2pkaqd-UfJe_HhHCUFTUifE6Bh96_k80sQDA,6348
 k1lib/cli/init.py,sha256=2FaWeRqZnb--XWV4Xpo0z4ANDdyWpNQlHKkALtOGHKQ,18351
 k1lib/cli/inp.py,sha256=BRwyBjLmo6DZbl0S3XZzKv5hnA27lDHgW6jJPSIYXGE,25961
 k1lib/cli/kcsv.py,sha256=YGUVVLTZGGujokhxtj5MfjU9t1jRGqp23d58JK8lhq0,623
 k1lib/cli/kxml.py,sha256=YQGutvKNm0_xAi_NhCNtuGey7fx3zZSmSo33kS--54c,4819
 k1lib/cli/mgi.py,sha256=aLke90nG89tgWLPwyKmTj3kM8yJnIBCJSrPS1jT8mUk,1915
-k1lib/cli/modifier.py,sha256=P401fVG1tn8D_6VCi3yok6EIScQIksR0Pkns0vMXX7I,60855
+k1lib/cli/modifier.py,sha256=c9NNvERa4xGxRMNHOaA-oVo19iKlWuXY1c-fW6gUkpQ,63021
 k1lib/cli/mol.py,sha256=wNFuCPXtdEcH4DRBbmYaLAWxtDzjN2MOKFX7ynJhaJs,694
 k1lib/cli/nb.py,sha256=LsNN7OFJ6KzAYKvZpm4fj9WRpsX6Srx6D_xpSTCV328,4038
 k1lib/cli/optimizations.py,sha256=iZ73DwLqZCxRm0sECVZ7A2nDxf5D4rsoSGzrKTgzGaI,3530
 k1lib/cli/output.py,sha256=JVOMyvvNmdf7CTpK8cTZesaJL4EDWZECpcDvg-NtHhQ,11762
 k1lib/cli/sam.py,sha256=_ersEPP2ue0Oa3AyftNjQu2PABpH4L7iFBbRJDOkeug,2394
-k1lib/cli/structural.py,sha256=4fa04Qe5Uoi7ZtKsQB1QGzkfkzkL6IsDsccOGOn-o3Q,49930
+k1lib/cli/structural.py,sha256=Ugn0Fb-0n0ardjjAvlfsfhRehLeUAszjvkW1odv6ZDU,49390
 k1lib/cli/trace.py,sha256=nzZgOyXqFJYkQfbpR0lpX0Nnp0bQHXPjk8sDUBIe2hk,10399
 k1lib/cli/typehint.py,sha256=VBYxrOQaSnu5266lNWpgXIhXF7htdT0FT_NEvXjYBVk,23319
 k1lib/cli/utils.py,sha256=XF-H1Ce5ssOw6Dp3htiosHce7xxTgxptrlUsMYxI7uE,21101
 k1lib/k1ui/__init__.py,sha256=8D5a8oKgqd6WA1RUkiKCn4l_PVemtyuckxQut0vDHXM,20
 k1lib/k1ui/main.py,sha256=PnmdOhkjYgRSZnDyGYNMYtQ5Nvcb1NhQ9yjfP_3QORI,61803
 k1lib/serve/__init__.py,sha256=8D5a8oKgqd6WA1RUkiKCn4l_PVemtyuckxQut0vDHXM,20
 k1lib/serve/main.py,sha256=Xh2SzgABfsBp2dRLUJRMftsG_We8ReVHYqXLi3ntMVA,10361
 k1lib/serve/suffix-dash.py,sha256=HMNJvB4d-PTHXDRDQTdYUKtzgirJ0LVnqqAkXxO0B4w,153
 k1lib/serve/suffix.py,sha256=UH3ITN6O2vzoha2f6v4bcQG3_Boav7VA7EC8wf8r9f8,642
-k1lib-1.3.8.6.data/data/k1lib/k1ui/256.model.state_dict.pth,sha256=Ga-UXlAJfUPNOZsvP_c1-1cfB2Hp_-oQ4ghdouX1d7g,2453826
-k1lib-1.3.8.6.data/data/k1lib/k1ui/mouseKey.pth,sha256=KULhK_gdK2Ppju9gQnv1zV2kf_A0K-vX2W7trY6DIg8,304735
-k1lib-1.3.8.6.data/data/k1lib/serve/main.html,sha256=gHFNqzE9JKb4eCwCJN-Du45jj75lDRED4Ico91T-b4g,20544
-k1lib-1.3.8.6.dist-info/LICENSE,sha256=psuy2wnTg9zacuCQ0dXfxS44iaa89aTgsNzHDzx4UGM,1049
-k1lib-1.3.8.6.dist-info/METADATA,sha256=WeoP8AohpmCIv7dTpCz6gEHGdF3rSUF9OmxtFX-__ns,3864
-k1lib-1.3.8.6.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-k1lib-1.3.8.6.dist-info/top_level.txt,sha256=xxWmqZzuThnLZn49Mse6A6j41-IVduPVnQW54imcOTA,6
-k1lib-1.3.8.6.dist-info/RECORD,,
+k1lib-1.3.8.7.data/data/k1lib/k1ui/256.model.state_dict.pth,sha256=Ga-UXlAJfUPNOZsvP_c1-1cfB2Hp_-oQ4ghdouX1d7g,2453826
+k1lib-1.3.8.7.data/data/k1lib/k1ui/mouseKey.pth,sha256=KULhK_gdK2Ppju9gQnv1zV2kf_A0K-vX2W7trY6DIg8,304735
+k1lib-1.3.8.7.data/data/k1lib/serve/main.html,sha256=gHFNqzE9JKb4eCwCJN-Du45jj75lDRED4Ico91T-b4g,20544
+k1lib-1.3.8.7.dist-info/LICENSE,sha256=psuy2wnTg9zacuCQ0dXfxS44iaa89aTgsNzHDzx4UGM,1049
+k1lib-1.3.8.7.dist-info/METADATA,sha256=RM3SL_e6mPqw-myE63EF_VYKikyn4sSS_U1_Dye7GQU,3864
+k1lib-1.3.8.7.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+k1lib-1.3.8.7.dist-info/top_level.txt,sha256=xxWmqZzuThnLZn49Mse6A6j41-IVduPVnQW54imcOTA,6
+k1lib-1.3.8.7.dist-info/RECORD,,
```

